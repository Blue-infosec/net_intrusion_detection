{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "author=\"Jumabek Alikhanov\"\n",
    "date = 'Nov 17,2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Final Project material for the \"Deep Learning\" class I took  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset from https://www.unb.ca/cic/datasets/ids-2017.html\n",
    "We only need CSV files that is preprocessed and labeled for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataroot = 'MachineLearningCVE/'\n",
    "SEED =2 \n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearningCVE/*.pcap_ISCX.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juma/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/juma/.local/lib/python3.6/site-packages/ipykernel_launcher.py:3: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2830743 flow records read which has 79 feature dimension\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "from preprocessing import load_data\n",
    "X,y = load_data(dataroot) # reads csv file and returns np array of X,y -> of shape (N,D) and (N,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imbalance\n",
    "1. It is curucial to adress this issue in order to get decent performance\n",
    "2. It also affects evaluation, we should calculate  `balanced accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2830743, 76) (2830743,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from preprocessing import balance_data, normalize\n",
    "\n",
    "X = normalize(X)\n",
    "#X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%autoreload 2\n",
    "from neural_network import NetClassifier\n",
    "\n",
    "def ensure_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "def getClassifier(args=None,runs_dir=None):\n",
    "    if args is not None:\n",
    "        (_,optim,lr,reg,batch_size,input_dim,num_class) = args\n",
    "    if runs_dir is not None:\n",
    "        ensure_dir(runs_dir)\n",
    "    \n",
    "    num_epochs = 60\n",
    "    \n",
    "    clf = NetClassifier(input_dim,num_class,lr=lr,reg=reg,num_epochs=num_epochs,\n",
    "                        batch_size=batch_size,runs_dir=runs_dir,use_batchnorm=True)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_1e-05_reg_1e-06_bs_5120 model trained with batch_size = 5120, seen 59 epochs and 300 mini batches\n",
      "Model is trained in 1.256474494934082 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_1e-05_reg_1e-05_bs_5120 model trained with batch_size = 5120, seen 59 epochs and 150 mini batches\n",
      "Model is trained in 1.2294058799743652 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_1e-05_reg_0.0001_bs_5120 model trained with batch_size = 5120, seen 59 epochs and 100 mini batches\n",
      "Model is trained in 1.2898533344268799 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_1e-05_reg_0.001_bs_5120 model trained with batch_size = 5120, seen 59 epochs and 350 mini batches\n",
      "Model is trained in 1.2325313091278076 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_0.0001_reg_1e-06_bs_5120 model trained with batch_size = 5120, seen 59 epochs and 200 mini batches\n",
      "Model is trained in 1.2824585437774658 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_0.0001_reg_1e-05_bs_5120 model trained with batch_size = 5120, seen 57 epochs and 0 mini batches\n",
      "Model is trained in 1.2349975109100342 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_0.0001_reg_0.0001_bs_5120 model trained with batch_size = 5120, seen 12 epochs and 200 mini batches\n",
      "Model is trained in 1.2236905097961426 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_0.0001_reg_0.001_bs_5120 model trained with batch_size = 5120, seen 37 epochs and 300 mini batches\n",
      "Model is trained in 1.289259672164917 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_0.0003_reg_1e-06_bs_5120 model trained with batch_size = 5120, seen 51 epochs and 100 mini batches\n",
      "Model is trained in 1.2362353801727295 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_0.0003_reg_1e-05_bs_5120 model trained with batch_size = 5120, seen 14 epochs and 50 mini batches\n",
      "Model is trained in 1.2889935970306396 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_0.0003_reg_0.0001_bs_5120 model trained with batch_size = 5120, seen 42 epochs and 200 mini batches\n",
      "Model is trained in 1.2364847660064697 sec\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_0.0003_reg_0.001_bs_5120 model trained with batch_size = 5120, seen 52 epochs and 300 mini batches\n",
      "Model is trained in 1.3015468120574951 sec\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "K=5\n",
    "X = X_train\n",
    "Y = y_train\n",
    "results = {}\n",
    "skf = StratifiedKFold(n_splits=K,random_state=SEED)\n",
    "\n",
    "#hyper-params\n",
    "batch_size = 5*1024 # increasing batch size with more gpu added\n",
    "optim = 'Adam'\n",
    "\n",
    "N,input_dim = X.shape\n",
    "num_class = len(np.unique(y_train))\n",
    "\n",
    "num_layers = 3\n",
    "run='3_2'\n",
    "lr = 1e-3 #best_lr\n",
    "reg = 1e-5 #best_reg\n",
    "\n",
    "for fold_index, (train_index,val_index) in enumerate(skf.split(X,Y)): \n",
    "    print('---------------------------------------------')\n",
    "    print('Fold #{}'.format(fold_index))    \n",
    "    X_train = X[train_index]\n",
    "    y_train = Y[train_index]\n",
    "    X_val = X[val_index]\n",
    "    y_val = Y[val_index]\n",
    "\n",
    "    classifier_args = ('softmax',optim,lr,reg,batch_size,input_dim,num_class)\n",
    "    config =  '{}_layer_relu_nn/{}th_run/optim_{}_lr_{}_reg_{}_bs_{}'.format(num_layers,run,optim,lr,reg,batch_size)\n",
    "    runs_dir = join(dataroot,'runs',config)\n",
    "        \n",
    "    X_train,y_train = balance_data(X_train,y_train)\n",
    "\n",
    "    tick = time.time()\n",
    "    clf = getClassifier(classifier_args,runs_dir)\n",
    "        \n",
    "    clf.fit(X_train,y_train,X_val,y_val,verbose=False)\n",
    "    raw_pred,pred = clf.predict(X_val,eval_mode=True)\n",
    "    acc = metrics.accuracy_score(y_val,pred)*100        \n",
    "    balanced_acc = metrics.balanced_accuracy_score(y_val,pred)*100\n",
    "    \n",
    "    raw_pred,pred = clf.predict(X_test,eval_mode=True)    \n",
    "    test_acc = metrics.balanced_accuracy_score(y_test,pred)*100\n",
    "    print('val acc:',acc)\n",
    "    print('balanced val acc: ',balanced_acc)\n",
    "    print('balanced test acc: ',test_acc)\n",
    "    \n",
    "    results[fold_index]= (acc,balanced_acc,test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_0.0001_reg_1e-05_bs_5120 model trained with batch_size = 5120, seen 57 epochs and 0 mini batches\n",
      "Loaded MachineLearningCVE/runs/5_layer_relu_nn/5th_run/optim_Adam_lr_0.0001_reg_1e-05_bs_5120 model trained with batch_size = 5120, seen 57 epochs and 0 mini batches\n",
      "\n",
      "val acc of best model  91.1445743762908\n",
      "test acc of best model  89.12953471998712\n"
     ]
    }
   ],
   "source": [
    "raw_pred,pred = best_model.predict(X_test,eval_mode=True)        \n",
    "test_acc = metrics.balanced_accuracy_score(y_test,pred)*100\n",
    "\n",
    "raw_pred,pred = best_model.predict(X_val,eval_mode=True)        \n",
    "val_acc = metrics.balanced_accuracy_score(y_val,pred)*100\n",
    "print()\n",
    "print(\"val acc of best model \",val_acc)\n",
    "print(\"test acc of best model \",test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cross-validation results\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "x_scatter = [math.log10(x[0]) for x in results]\n",
    "y_scatter = [math.log10(x[1]) for x in results]\n",
    "\n",
    "\n",
    "# plot validation accuracy\n",
    "marker_size=100\n",
    "colors = [results[x] for x in results] # default size of markers is 20\n",
    "\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar()\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('Net intrusion(CIC-IDS-2017) validation accuracy')\n",
    "plt.savefig('MachineLearningCVE/5_layers_relu_{}th_run.png'.format(run))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
