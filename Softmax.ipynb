{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "author=\"Jumabek Alikhanov\"\n",
    "date = 'Nov 19,2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataroot = 'MachineLearningCVE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataroot,file_ending):\n",
    "    if file_ending==None:\n",
    "        print(\"please specify file ending pattern for glob\")\n",
    "        exit()\n",
    "    print(join(dataroot,file_ending))\n",
    "    filenames = [i for i in glob.glob(join(dataroot,file_ending))]\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in filenames],sort=False)\n",
    "    return combined_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/juma/code/courses/Semester3/DeepLearning/intrusion_detection/MachineLearningCVE/*.pcap_ISCX.csv\n"
     ]
    }
   ],
   "source": [
    "# read and preprocess data\n",
    "\n",
    "data = read_data(dataroot,'*.pcap_ISCX.csv')\n",
    "# there is white spaces in columns names e.g. ' Destination Port'\n",
    "# So strip the whitespace from  column names\n",
    "data = data.rename(columns=lambda x: x.strip())\n",
    "df_label = data['Label']\n",
    "data = data.drop(columns=['Flow Packets/s','Flow Bytes/s','Label'])\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "data = data.astype(float).apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets count if there is NaN values in our dataframe( AKA missing features)\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the above data is imbalanced we do oversampling to balance data\n",
    "def balance_data(X,y):\n",
    "    unique,counts = np.unique(y,return_counts=True)\n",
    "    mean_samples_per_class = int(round(np.mean(counts)))\n",
    "    new_X = np.empty((0,X.shape[1]))\n",
    "    new_y = np.empty((0),dtype=int)\n",
    "    for i,c in enumerate(unique):\n",
    "        temp_x = X[y==c]\n",
    "        indices = np.random.choice(temp_x.shape[0],mean_samples_per_class)\n",
    "        new_X = np.concatenate((new_X,temp_x[indices]),axis=0)\n",
    "        temp_y = np.ones(mean_samples_per_class,dtype=int)*c\n",
    "        new_y = np.concatenate((new_y,temp_y),axis=0)\n",
    "\n",
    "    # in order to break class order in data we need shuffling\n",
    "    indices = np.arange(new_y.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    new_X =  new_X[indices,:]\n",
    "    new_y = new_y[indices]\n",
    "    return (new_X,new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chganges label from string to integer/index\n",
    "def encode_label(Y_str):\n",
    "    labels_d = make_value2index(np.unique(Y_str))\n",
    "    Y = [labels_d[y_str] for y_str  in Y_str]\n",
    "    Y = np.array(Y)\n",
    "    return np.array(Y)\n",
    "\n",
    "def make_value2index(attacks):\n",
    "    #make dictionary\n",
    "    attacks = sorted(attacks)\n",
    "    d = {}\n",
    "    counter=0\n",
    "    for attack in attacks:\n",
    "        d[attack] = counter\n",
    "        counter+=1\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "def normilize(data):\n",
    "        data = data.astype(np.float32)\n",
    "       \n",
    "        eps = 1e-15\n",
    "\n",
    "        mask = data==-1\n",
    "        data[mask]=0\n",
    "        mean_i = np.mean(data,axis=0)\n",
    "        min_i = np.min(data,axis=0) #  to leave -1 (missing features) values as is and exclude in normilizing\n",
    "        max_i = np.max(data,axis=0)\n",
    "\n",
    "        r = max_i-min_i+eps\n",
    "        data = (data-mean_i)/r  # zero centered \n",
    "\n",
    "        #deal with missing features -1\n",
    "        data[mask] = 0\n",
    "        \n",
    "        nan_index = np.isnan(data)\n",
    "        nan_data = data[nan_index]\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2830743, 76) (2830743,)\n"
     ]
    }
   ],
   "source": [
    "data_np = data.values # convert to numpy array\n",
    "X = data_np\n",
    "X = normilize(X)\n",
    "y = df_label.values\n",
    "y = encode_label(y)\n",
    "N = X.shape[0]\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%autoreload 2\n",
    "from shallows import LinearClassifier\n",
    "\n",
    "def ensure_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "\n",
    "def getClassifier(args=None,runs_dir=None):\n",
    "    if args is not None:\n",
    "        (_,optim,lr,reg,batch_size,input_dim,num_class) = args\n",
    "    if runs_dir is not None:\n",
    "        ensure_dir(runs_dir)\n",
    "    \n",
    "    num_epochs = 10\n",
    "    \n",
    "    clf = LinearClassifier('softmax',input_dim,num_class,lr=lr,reg=reg,num_epochs=num_epochs,batch_size=batch_size,runs_dir=runs_dir)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_final_test, y_train, y__final_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-371fe9166f7c>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-371fe9166f7c>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    optim = 'Adam'from sklearn.model_selection import train_test_split\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#hyper-params\n",
    "batch_size = 1024\n",
    "optim = 'Adam'\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "num_class = len(np.unique(y_train))\n",
    "\n",
    "accuracies = {}\n",
    "learning_rates = np.random.uniform(1e-4,1e-2,6)\n",
    "regularizations = np.random.uniform(1e-7,1e-5,2)\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "num_layers = 3\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularizations:\n",
    "\n",
    "        classifier_args = ('softmax',optim,lr,reg,batch_size,input_dim,num_class)\n",
    "        config =  'softmax/1st_run/optim_{}_lr_{}_reg_{}_bs_{}'.format(num_layers,optim,lr,reg,batch_size)\n",
    "        runs_dir = join(dataroot,'runs',config)\n",
    "        \n",
    "        X_train = X_train.astype(float)\n",
    "        y_train = y_train.astype(int)\n",
    "        p = np.random.permutation(len(y_train))\n",
    "        X_train = X_train[p]\n",
    "        y_train = y_train[p]\n",
    "        X_train,y_train = balance_data(X_train,y_train)\n",
    "\n",
    "        tick = time.time()\n",
    "        clf = getClassifier(classifier_args,runs_dir)\n",
    "        \n",
    "        clf.fit(X_train,y_train,verbose=False)\n",
    "        pred = clf.predict(X_val)\n",
    "        \n",
    "        acc = metrics.balanced_accuracy_score(y_val,pred)\n",
    "        if acc >best_acc:\n",
    "            best_model = clf\n",
    "            best_acc = acc\n",
    "        accuracies[(lr,reg)]=acc\n",
    "        tock = time.time()\n",
    "        print(\"Model is trained in {.0f}sec\".format(tock-tick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cross-validation results\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "x_scatter = [math.log10(x[0]) for x in results]\n",
    "y_scatter = [math.log10(x[1]) for x in results]\n",
    "\n",
    "\n",
    "# plot validation accuracy\n",
    "marker_size=100\n",
    "colors = [results[x] for x in results] # default size of markers is 20\n",
    "\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar()\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('Net intrusion(CIC-IDS-2017) validation accuracy')\n",
    "plt.savefig('MachineLearningCVE/runs/softmax/1st_run.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
