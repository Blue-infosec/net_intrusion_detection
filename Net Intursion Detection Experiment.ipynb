{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "author=\"Jumabek Alikhanov\"\n",
    "date = 'Nov 17,2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Final Project material for the \"Deep Learning\" class I took  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset from https://www.unb.ca/cic/datasets/ids-2017.html\n",
    "We only need CSV files that is preprocessed and labeled for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataroot = 'MachineLearningCVE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataroot,file_ending):\n",
    "    if file_ending==None:\n",
    "        print(\"please specify file ending pattern for glob\")\n",
    "        exit()\n",
    "    print(join(dataroot,file_ending))\n",
    "    filenames = [i for i in glob.glob(join(dataroot,file_ending))]\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in filenames],sort=False)\n",
    "    return combined_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MachineLearningCVE/*.pcap_ISCX.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juma/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/juma/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "data = read_data(dataroot,'*.pcap_ISCX.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2830743 flow records read which has 79 feature dimension\n"
     ]
    }
   ],
   "source": [
    "num_records,num_features = data.shape\n",
    "print(\"{} flow records read which has {} feature dimension\".format(num_records,num_features))\n",
    "# there is white spaces in columns names e.g. ' Destination Port'\n",
    "# So strip the whitespace from  column names\n",
    "data = data.rename(columns=lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_label = data['Label']\n",
    "data = data.drop(columns=['Flow Packets/s','Flow Bytes/s','Label'])\n",
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(float).apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets count if there is NaN values in our dataframe( AKA missing features)\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1266342.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2664.0</td>\n",
       "      <td>6954.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.975610</td>\n",
       "      <td>109.864573</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1319353.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2664.0</td>\n",
       "      <td>6954.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.975610</td>\n",
       "      <td>109.864573</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>22.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1303488.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2728.0</td>\n",
       "      <td>6634.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.536585</td>\n",
       "      <td>110.129945</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>35396.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Destination Port  Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0              22.0      1266342.0               41.0                    44.0   \n",
       "1              22.0      1319353.0               41.0                    44.0   \n",
       "2              22.0          160.0                1.0                     1.0   \n",
       "3              22.0      1303488.0               41.0                    42.0   \n",
       "4           35396.0           77.0                1.0                     2.0   \n",
       "\n",
       "   Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "0                       2664.0                       6954.0   \n",
       "1                       2664.0                       6954.0   \n",
       "2                          0.0                          0.0   \n",
       "3                       2728.0                       6634.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                  456.0                    0.0               64.975610   \n",
       "1                  456.0                    0.0               64.975610   \n",
       "2                    0.0                    0.0                0.000000   \n",
       "3                  456.0                    0.0               66.536585   \n",
       "4                    0.0                    0.0                0.000000   \n",
       "\n",
       "   Fwd Packet Length Std  ...  act_data_pkt_fwd  min_seg_size_forward  \\\n",
       "0             109.864573  ...              24.0                  32.0   \n",
       "1             109.864573  ...              24.0                  32.0   \n",
       "2               0.000000  ...               0.0                  32.0   \n",
       "3             110.129945  ...              24.0                  32.0   \n",
       "4               0.000000  ...               0.0                  32.0   \n",
       "\n",
       "   Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \\\n",
       "0          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "1          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "2          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "3          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "4          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "\n",
       "   Idle Max  Idle Min  \n",
       "0       0.0       0.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       0.0  \n",
       "3       0.0       0.0  \n",
       "4       0.0       0.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN                        2273097\n",
       "DoS Hulk                       231073\n",
       "PortScan                       158930\n",
       "DDoS                           128027\n",
       "DoS GoldenEye                   10293\n",
       "FTP-Patator                      7938\n",
       "SSH-Patator                      5897\n",
       "DoS slowloris                    5796\n",
       "DoS Slowhttptest                 5499\n",
       "Bot                              1966\n",
       "Web Attack ï¿½ Brute Force         1507\n",
       "Web Attack ï¿½ XSS                  652\n",
       "Infiltration                       36\n",
       "Web Attack ï¿½ Sql Injection         21\n",
       "Heartbleed                         11\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print label distribution\n",
    "pd.DataFrame(df_label.value_counts()).to_csv(join(dataroot,'class_distribution.csv'))\n",
    "df_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imbalance\n",
    "1. It is curucial to adress this issue in order to get decent performance\n",
    "2. It also affects evaluation, we should calculate accuracy for balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the above data is imbalanced we do oversampling to balance data\n",
    "def balance_data(X,y):\n",
    "    unique,counts = np.unique(y,return_counts=True)\n",
    "    mean_samples_per_class = int(round(np.mean(counts)))\n",
    "    new_X = np.empty((0,X.shape[1]))\n",
    "    new_y = np.empty((0),dtype=int)\n",
    "    for i,c in enumerate(unique):\n",
    "        temp_x = X[y==c]\n",
    "        indices = np.random.choice(temp_x.shape[0],mean_samples_per_class)\n",
    "        new_X = np.concatenate((new_X,temp_x[indices]),axis=0)\n",
    "        temp_y = np.ones(mean_samples_per_class,dtype=int)*c\n",
    "        new_y = np.concatenate((new_y,temp_y),axis=0)\n",
    "\n",
    "    # in order to break class order in data we need shuffling\n",
    "    indices = np.arange(new_y.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    new_X =  new_X[indices,:]\n",
    "    new_y = new_y[indices]\n",
    "    return (new_X,new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chganges label from string to integer/index\n",
    "def encode_label(Y_str):\n",
    "    labels_d = make_value2index(np.unique(Y_str))\n",
    "    Y = [labels_d[y_str] for y_str  in Y_str]\n",
    "    Y = np.array(Y)\n",
    "    return np.array(Y)\n",
    "\n",
    "def make_value2index(attacks):\n",
    "    #make dictionary\n",
    "    attacks = sorted(attacks)\n",
    "    d = {}\n",
    "    counter=0\n",
    "    for attack in attacks:\n",
    "        d[attack] = counter\n",
    "        counter+=1\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "def normilize(data):\n",
    "        data = data.astype(np.float32)\n",
    "       \n",
    "        eps = 1e-15\n",
    "        if len(data[data>=0])<=0: # make sure we actually have at least one none -1 feature\n",
    "            return\n",
    "\n",
    "        mask = data==-1\n",
    "        data[mask]=0\n",
    "        mean_i = np.mean(data,axis=0)\n",
    "        min_i = np.min(data,axis=0) #  to leave -1 features as is and exclude in normilizing\n",
    "        max_i = np.max(data,axis=0)\n",
    "\n",
    "        r = max_i-min_i+eps\n",
    "        data = (data-mean_i)/r  # zero centered norm [-0.5,0.5]\n",
    "        #deal with edge case -1\n",
    "        data[mask] = 0\n",
    "        \n",
    "        nan_index = np.isnan(data)\n",
    "        nan_data = data[nan_index]\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2830743, 76) (2830743,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "data_np = data.values # convert to numpy array\n",
    "X = data_np\n",
    "X = normilize(X)\n",
    "#X = preprocessing.scale(X)\n",
    "y = df_label.values\n",
    "y = encode_label(y)\n",
    "N = X.shape[0]\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(283074, 76) (283074,)\n"
     ]
    }
   ],
   "source": [
    "#until we get all of our code to work, we use smaller portion of the dataset to saves us time\n",
    "X_toy = X[:N//10]\n",
    "y_toy = y[:N//10]\n",
    "print(X_toy.shape,y_toy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%autoreload 2\n",
    "from shallows import LinearClassifier\n",
    "from neural_network import NetClassifier\n",
    "\n",
    "def ensure_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "def getClassifier(args=None,runs_dir=None):\n",
    "    if args is not None:\n",
    "        (_,optim,lr,reg,batch_size,input_dim,num_class) = args\n",
    "    if runs_dir is not None:\n",
    "        ensure_dir(runs_dir)\n",
    "    \n",
    "    num_epochs = 20\n",
    "    \n",
    "    clf = NetClassifier(input_dim,num_class,lr=lr,reg=reg,num_epochs=num_epochs,\n",
    "                        batch_size=batch_size,runs_dir=runs_dir,use_batchnorm=True)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated time is 0.0 minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#hyper-params\n",
    "batch_size = 1024\n",
    "optim = 'Adam'\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "num_class = len(np.unique(y_train))\n",
    "\n",
    "accuracies = {}\n",
    "learning_rates = []#[1e-3]\n",
    "regularizations = [1e-5]\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "num_layers = 5\n",
    "\n",
    "e_time = len(learning_rates)*len(regularizations)*800/60\n",
    "print(\"estimated time is {} minutes\".format(e_time))\n",
    "for lr in learning_rates:\n",
    "    for reg in regularizations:\n",
    "\n",
    "        classifier_args = ('softmax',optim,lr,reg,batch_size,input_dim,num_class)\n",
    "        config =  '{}_layer_nn/3th_run/optim_{}_lr_{}_reg_{}_bs_{}'.format(num_layers,optim,lr,reg,batch_size)\n",
    "        runs_dir = join(dataroot,'runs',config)\n",
    "        \n",
    "        X_train = X_train.astype(float)\n",
    "        y_train = y_train.astype(int)\n",
    "        p = np.random.permutation(len(y_train))\n",
    "        X_train = X_train[p]\n",
    "        y_train = y_train[p]\n",
    "        X_train,y_train = balance_data(X_train,y_train)\n",
    "\n",
    "        tick = time.time()\n",
    "        clf = getClassifier(classifier_args,runs_dir)\n",
    "        \n",
    "        clf.fit(X_train,y_train,X_val,y_val,verbose=False)\n",
    "        raw_pred,pred = clf.predict(X_val,eval_mode=True)\n",
    "        \n",
    "        acc = metrics.balanced_accuracy_score(y_val,pred)\n",
    "        if acc >best_acc:\n",
    "            best_model = clf\n",
    "            best_acc = acc\n",
    "        accuracies[(lr,reg)]=acc\n",
    "        tock = time.time()\n",
    "        print(\"Model is trained in {} sec\".format(tock-tick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensamble\n",
    "learning_rates = [1e-3]\n",
    "regularizations = [1e-5]\n",
    "def get_ensamble_accuracy(X,y):\n",
    "    raw_pred_sum = np.zeros((y.shape[0],num_class))\n",
    "    num_models = 1#len(learning_rates)*len(regularizations)\n",
    "    for lr in learning_rates:\n",
    "        for reg in regularizations:\n",
    "            classifier_args = ('softmax',optim,lr,reg,batch_size,input_dim,num_class)\n",
    "            config =  '{}_layer_nn/3th_run/optim_{}_lr_{}_reg_{}_bs_{}'.format(num_layers,optim,lr,reg,batch_size)\n",
    "            runs_dir = join(dataroot,'runs',config)\n",
    "            clf = getClassifier(classifier_args,runs_dir)        \n",
    "            raw_pred,pred= clf.predict(X,eval_mode=True)\n",
    "            print(raw_pred.shape,pred.shape)\n",
    "            raw_pred_sum += raw_pred\n",
    "                        \n",
    "    raw_pred =raw_pred_sum/num_models\n",
    "    pred = np.argmax(raw_pred,axis=1)\n",
    "    acc = metrics.balanced_accuracy_score(y,pred)*100\n",
    "    print('{0} model ensamble acc is {1:.2f} '.format(num_models,acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model with has batch_size = {}, seen {} examlpes from dataset of size {} 1024 39813120 1991\n",
      "(566149, 15) (566149,)\n",
      "1 model ensamble acc is 90.55 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90.54967695995119"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ensamble_accuracy(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-55782ae95326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbalanced_accuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test acc of best model \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "raw_pred,pred = best_model.predict(X_test,eval_mode=True)\n",
    "        \n",
    "acc = metrics.balanced_accuracy_score(y_test,pred)*100\n",
    "print(\"Test acc of best model \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracies for CV\n",
    "for x in accuracies:\n",
    "    print(x)\n",
    "    print(accuracies[x])\n",
    "results = accuracies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cross-validation results\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "x_scatter = [math.log10(x[0]) for x in results]\n",
    "y_scatter = [math.log10(x[1]) for x in results]\n",
    "\n",
    "\n",
    "# plot validation accuracy\n",
    "marker_size=100\n",
    "colors = [results[x] for x in results] # default size of markers is 20\n",
    "\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar()\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('Net intrusion(CIC-IDS-2017) validation accuracy')\n",
    "plt.savefig('MachineLearningCVE/5_layers_3th_run.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
