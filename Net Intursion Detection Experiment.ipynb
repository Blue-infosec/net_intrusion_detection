{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "author=\"Jumabek Alikhanov\"\n",
    "date = 'Nov 17,2019'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Final Project material for the \"Deep Learning\" class I took  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset from https://www.unb.ca/cic/datasets/ids-2017.html\n",
    "We only need CSV files that is preprocessed and labeled for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "from os.path import join\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "dataroot = '/media/juma/code/courses/Semester3/DeepLearning/intrusion_detection/MachineLearningCVE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataroot,file_ending):\n",
    "    if file_ending==None:\n",
    "        print(\"please specify file ending pattern for glob\")\n",
    "        exit()\n",
    "    print(join(dataroot,file_ending))\n",
    "    filenames = [i for i in glob.glob(join(dataroot,file_ending))]\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in filenames],sort=False)\n",
    "    return combined_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/juma/code/courses/Semester3/DeepLearning/intrusion_detection/MachineLearningCVE/*.pcap_ISCX.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juma/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/juma/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2830743 entries, 0 to 692702\n",
      "Data columns (total 79 columns):\n",
      " Destination Port               int64\n",
      " Flow Duration                  int64\n",
      " Total Fwd Packets              int64\n",
      " Total Backward Packets         int64\n",
      "Total Length of Fwd Packets     int64\n",
      " Total Length of Bwd Packets    int64\n",
      " Fwd Packet Length Max          int64\n",
      " Fwd Packet Length Min          int64\n",
      " Fwd Packet Length Mean         float64\n",
      " Fwd Packet Length Std          float64\n",
      "Bwd Packet Length Max           int64\n",
      " Bwd Packet Length Min          int64\n",
      " Bwd Packet Length Mean         float64\n",
      " Bwd Packet Length Std          float64\n",
      "Flow Bytes/s                    object\n",
      " Flow Packets/s                 object\n",
      " Flow IAT Mean                  float64\n",
      " Flow IAT Std                   float64\n",
      " Flow IAT Max                   int64\n",
      " Flow IAT Min                   int64\n",
      "Fwd IAT Total                   int64\n",
      " Fwd IAT Mean                   float64\n",
      " Fwd IAT Std                    float64\n",
      " Fwd IAT Max                    int64\n",
      " Fwd IAT Min                    int64\n",
      "Bwd IAT Total                   int64\n",
      " Bwd IAT Mean                   float64\n",
      " Bwd IAT Std                    float64\n",
      " Bwd IAT Max                    int64\n",
      " Bwd IAT Min                    int64\n",
      "Fwd PSH Flags                   int64\n",
      " Bwd PSH Flags                  int64\n",
      " Fwd URG Flags                  int64\n",
      " Bwd URG Flags                  int64\n",
      " Fwd Header Length              int64\n",
      " Bwd Header Length              int64\n",
      "Fwd Packets/s                   float64\n",
      " Bwd Packets/s                  float64\n",
      " Min Packet Length              int64\n",
      " Max Packet Length              int64\n",
      " Packet Length Mean             float64\n",
      " Packet Length Std              float64\n",
      " Packet Length Variance         float64\n",
      "FIN Flag Count                  int64\n",
      " SYN Flag Count                 int64\n",
      " RST Flag Count                 int64\n",
      " PSH Flag Count                 int64\n",
      " ACK Flag Count                 int64\n",
      " URG Flag Count                 int64\n",
      " CWE Flag Count                 int64\n",
      " ECE Flag Count                 int64\n",
      " Down/Up Ratio                  int64\n",
      " Average Packet Size            float64\n",
      " Avg Fwd Segment Size           float64\n",
      " Avg Bwd Segment Size           float64\n",
      " Fwd Header Length.1            int64\n",
      "Fwd Avg Bytes/Bulk              int64\n",
      " Fwd Avg Packets/Bulk           int64\n",
      " Fwd Avg Bulk Rate              int64\n",
      " Bwd Avg Bytes/Bulk             int64\n",
      " Bwd Avg Packets/Bulk           int64\n",
      "Bwd Avg Bulk Rate               int64\n",
      "Subflow Fwd Packets             int64\n",
      " Subflow Fwd Bytes              int64\n",
      " Subflow Bwd Packets            int64\n",
      " Subflow Bwd Bytes              int64\n",
      "Init_Win_bytes_forward          int64\n",
      " Init_Win_bytes_backward        int64\n",
      " act_data_pkt_fwd               int64\n",
      " min_seg_size_forward           int64\n",
      "Active Mean                     float64\n",
      " Active Std                     float64\n",
      " Active Max                     int64\n",
      " Active Min                     int64\n",
      "Idle Mean                       float64\n",
      " Idle Std                       float64\n",
      " Idle Max                       int64\n",
      " Idle Min                       int64\n",
      " Label                          object\n",
      "dtypes: float64(22), int64(54), object(3)\n",
      "memory usage: 1.7+ GB\n"
     ]
    }
   ],
   "source": [
    "data = read_data(dataroot,'*.pcap_ISCX.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2830743 flow records read which has 79 feature dimension\n"
     ]
    }
   ],
   "source": [
    "num_records,num_features = data.shape\n",
    "print(\"{} flow records read which has {} feature dimension\".format(num_records,num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is white spaces in columns names e.g. ' Destination Port'\n",
    "# So strip the whitespace from  column names\n",
    "data = data.rename(columns=lambda x: x.strip())\n",
    "df_label = data['Label']\n",
    "data = data.drop(columns=['Flow Packets/s','Flow Bytes/s','Label'])\n",
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(float).apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets count if there is NaN values in our dataframe( AKA missing features)\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Fwd Packet Length Max</th>\n",
       "      <th>Fwd Packet Length Min</th>\n",
       "      <th>Fwd Packet Length Mean</th>\n",
       "      <th>Fwd Packet Length Std</th>\n",
       "      <th>...</th>\n",
       "      <th>act_data_pkt_fwd</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54865.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55054.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55055.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46236.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54863.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Destination Port  Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
       "0           54865.0            3.0                2.0                     0.0   \n",
       "1           55054.0          109.0                1.0                     1.0   \n",
       "2           55055.0           52.0                1.0                     1.0   \n",
       "3           46236.0           34.0                1.0                     1.0   \n",
       "4           54863.0            3.0                2.0                     0.0   \n",
       "\n",
       "   Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
       "0                         12.0                          0.0   \n",
       "1                          6.0                          6.0   \n",
       "2                          6.0                          6.0   \n",
       "3                          6.0                          6.0   \n",
       "4                         12.0                          0.0   \n",
       "\n",
       "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
       "0                    6.0                    6.0                     6.0   \n",
       "1                    6.0                    6.0                     6.0   \n",
       "2                    6.0                    6.0                     6.0   \n",
       "3                    6.0                    6.0                     6.0   \n",
       "4                    6.0                    6.0                     6.0   \n",
       "\n",
       "   Fwd Packet Length Std  ...  act_data_pkt_fwd  min_seg_size_forward  \\\n",
       "0                    0.0  ...               1.0                  20.0   \n",
       "1                    0.0  ...               0.0                  20.0   \n",
       "2                    0.0  ...               0.0                  20.0   \n",
       "3                    0.0  ...               0.0                  20.0   \n",
       "4                    0.0  ...               1.0                  20.0   \n",
       "\n",
       "   Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \\\n",
       "0          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "1          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "2          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "3          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "4          0.0         0.0         0.0         0.0        0.0       0.0   \n",
       "\n",
       "   Idle Max  Idle Min  \n",
       "0       0.0       0.0  \n",
       "1       0.0       0.0  \n",
       "2       0.0       0.0  \n",
       "3       0.0       0.0  \n",
       "4       0.0       0.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BENIGN                        2273097\n",
       "DoS Hulk                       231073\n",
       "PortScan                       158930\n",
       "DDoS                           128027\n",
       "DoS GoldenEye                   10293\n",
       "FTP-Patator                      7938\n",
       "SSH-Patator                      5897\n",
       "DoS slowloris                    5796\n",
       "DoS Slowhttptest                 5499\n",
       "Bot                              1966\n",
       "Web Attack � Brute Force         1507\n",
       "Web Attack � XSS                  652\n",
       "Infiltration                       36\n",
       "Web Attack � Sql Injection         21\n",
       "Heartbleed                         11\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print label distribution\n",
    "pd.DataFrame(df_label.value_counts()).to_csv(join(dataroot,'class_distribution.csv'))\n",
    "df_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the above data is imbalanced we do oversampling to balance data\n",
    "def balance_data(X,y):\n",
    "    unique,counts = np.unique(y,return_counts=True)\n",
    "    mean_samples_per_class = int(round(np.mean(counts)))\n",
    "    new_X = np.empty((0,X.shape[1]))\n",
    "    new_y = np.empty((0),dtype=int)\n",
    "    for i,c in enumerate(unique):\n",
    "        temp_x = X[y==c]\n",
    "        indices = np.random.choice(temp_x.shape[0],mean_samples_per_class)\n",
    "        new_X = np.concatenate((new_X,temp_x[indices]),axis=0)\n",
    "        temp_y = np.ones(mean_samples_per_class,dtype=int)*c\n",
    "        new_y = np.concatenate((new_y,temp_y),axis=0)\n",
    "\n",
    "    # in order to break class order in data we need shuffling\n",
    "    indices = np.arange(new_y.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    new_X =  new_X[indices,:]\n",
    "    new_y = new_y[indices]\n",
    "    return (new_X,new_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chganges label from string to integer/index\n",
    "def encode_label(Y_str):\n",
    "    labels_d = make_value2index(np.unique(Y_str))\n",
    "    Y = [labels_d[y_str] for y_str  in Y_str]\n",
    "    Y = np.array(Y)\n",
    "    return np.array(Y)\n",
    "\n",
    "def make_value2index(attacks):\n",
    "    #make dictionary\n",
    "    attacks = sorted(attacks)\n",
    "    d = {}\n",
    "    counter=0\n",
    "    for attack in attacks:\n",
    "        d[attack] = counter\n",
    "        counter+=1\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "def normilize(data):\n",
    "        data = data.astype(np.float32)\n",
    "       \n",
    "        eps = 1e-15\n",
    "        if len(data[data>=0])<=0: # make sure we actually have at least one none -1 feature\n",
    "            return\n",
    "\n",
    "        mask = data==-1\n",
    "        data[mask]=0\n",
    "        mean_i = np.mean(data,axis=0)\n",
    "        min_i = np.min(data,axis=0) #  to leave -1 features as is and exclude in normilizing\n",
    "        max_i = np.max(data,axis=0)\n",
    "\n",
    "        r = max_i-min_i+eps\n",
    "        data = (data-mean_i)/r  # zero centered norm [-0.5,0.5]\n",
    "        #deal with edge case -1\n",
    "        data[mask] = 0\n",
    "        \n",
    "        nan_index = np.isnan(data)\n",
    "        nan_data = data[nan_index]\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2830743, 76) (2830743,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "data_np = data.values # convert to numpy array\n",
    "X = data_np\n",
    "X = normilize(X)\n",
    "#X = preprocessing.scale(X)\n",
    "y = df_label.values\n",
    "y = encode_label(y)\n",
    "N = X.shape[0]\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(283074, 76) (283074,)\n"
     ]
    }
   ],
   "source": [
    "#until we get all of our code to work, we use smaller portion of the dataset to saves us time\n",
    "X_toy = X[:N//10]\n",
    "y_toy = y[:N//10]\n",
    "print(X_toy.shape,y_toy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%autoreload 2\n",
    "from shallows import LinearClassifier\n",
    "from neural_network import NetClassifier\n",
    "\n",
    "def ensure_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "\n",
    "def getClassifier(args=None,runs_dir=None):\n",
    "    if args is not None:\n",
    "        (_,optim,lr,reg,batch_size,input_dim,num_class) = args\n",
    "    if runs_dir is not None:\n",
    "        ensure_dir(runs_dir)\n",
    "    \n",
    "    num_epochs = 10\n",
    "    \n",
    "    clf = NetClassifier(input_dim,num_class,lr=lr,reg=reg,num_epochs=num_epochs,batch_size=batch_size,runs_dir=runs_dir)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_final_test, y_train, y__final_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9104986467684923"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9587344343371897"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#hyper-params\n",
    "batch_size = 1024\n",
    "optim = 'Adam'from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_final_test, y_train, y__final_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=2)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=2)\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "num_class = len(np.unique(y_train))\n",
    "\n",
    "accuracies = {}\n",
    "learning_rates = np.random.uniform(1e-4,1e-2,6)\n",
    "regularizations = np.random.uniform(1e-7,1e-5,2)\n",
    "best_model = None\n",
    "best_acc = -1\n",
    "num_layers = 3\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for reg in regularizations:\n",
    "\n",
    "        classifier_args = ('softmax',optim,lr,reg,batch_size,input_dim,num_class)\n",
    "        config =  '{}_layer_nn/3rd_run/optim_{}_lr_{}_reg_{}_bs_{}'.format(num_layers,optim,lr,reg,batch_size)\n",
    "        runs_dir = join(dataroot,'runs',config)\n",
    "        \n",
    "        X_train = X_train.astype(float)\n",
    "        y_train = y_train.astype(int)\n",
    "        p = np.random.permutation(len(y_train))\n",
    "        X_train = X_train[p]\n",
    "        y_train = y_train[p]\n",
    "        X_train,y_train = balance_data(X_train,y_train)\n",
    "\n",
    "        tick = time.time()\n",
    "        clf = getClassifier(classifier_args,runs_dir)\n",
    "        \n",
    "        clf.fit(X_train,y_train,verbose=False)\n",
    "        pred = clf.predict(X_val)\n",
    "        \n",
    "        acc = metrics.balanced_accuracy_score(y_val,pred)\n",
    "        if acc >best_acc:\n",
    "            best_model = clf\n",
    "            best_acc = acc\n",
    "        accuracies[(lr,reg)]=acc\n",
    "        tock = time.time()\n",
    "        print(\"Model is trained in {.0f}sec\".format(tock-tick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in accuracies:\n",
    "    print(x)\n",
    "    print(accuracies[x])\n",
    "results = accuracies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the cross-validation results\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "x_scatter = [math.log10(x[0]) for x in results]\n",
    "y_scatter = [math.log10(x[1]) for x in results]\n",
    "\n",
    "\n",
    "# plot validation accuracy\n",
    "marker_size=100\n",
    "colors = [results[x] for x in results] # default size of markers is 20\n",
    "\n",
    "plt.scatter(x_scatter, y_scatter, marker_size, c=colors, cmap=plt.cm.coolwarm)\n",
    "plt.colorbar()\n",
    "plt.xlabel('log learning rate')\n",
    "plt.ylabel('log regularization strength')\n",
    "plt.title('Net intrusion(CIC-IDS-2017) validation accuracy')\n",
    "plt.savefig('/media/juma/code/courses/Semester3/DeepLearning/intrusion_detection/MachineLearningCVE/3rd_run.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
